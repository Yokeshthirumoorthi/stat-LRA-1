<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Yokesh Thirumoorthi (STAT 564 FINALS)</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
        <link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        
        <script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
    </head>
    <body class="vscode-light">
        <h3 id="yokesh-thirumoorthi-stat-564-finals">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<h4 id="question-1">Question 1</h4>
<pre><code class="language-R"><div>    <span class="hljs-comment"># Import the libraries</span>
    <span class="hljs-keyword">library</span>(plotly)
    <span class="hljs-keyword">library</span>(segmented)

    <span class="hljs-comment"># Create the dataset:</span>
    Lotsize &lt;- c(<span class="hljs-number">100</span>,<span class="hljs-number">120</span>,<span class="hljs-number">140</span>,<span class="hljs-number">160</span>,<span class="hljs-number">180</span>,<span class="hljs-number">200</span>,<span class="hljs-number">220</span>,<span class="hljs-number">240</span>,<span class="hljs-number">260</span>,<span class="hljs-number">280</span>,<span class="hljs-number">300</span>)
    Cost &lt;- c(<span class="hljs-number">9.73</span>,<span class="hljs-number">9.61</span>,<span class="hljs-number">8.15</span>,<span class="hljs-number">6.98</span>,<span class="hljs-number">5.87</span>,<span class="hljs-number">4.98</span>,<span class="hljs-number">5.09</span>,<span class="hljs-number">4.79</span>,<span class="hljs-number">4.02</span>,<span class="hljs-number">4.46</span>,<span class="hljs-number">3.82</span>)
    data &lt;- data.frame(Lotsize,Cost)

    <span class="hljs-comment"># Visalize the dataset:</span>
    plot_ly(data,x=~Lotsize, y=~Cost, type=<span class="hljs-string">"scatter"</span>)

    <span class="hljs-comment"># Fit a linear regression</span>
    fit &lt;- lm(Cost ~ Lotsize, data=data)
    summary(fit)

    <span class="hljs-comment"># Output</span>
    <span class="hljs-comment"># Residuals:</span>
    <span class="hljs-comment">#     Min      1Q  Median      3Q     Max </span>
    <span class="hljs-comment"># -1.1564 -0.4091 -0.1154  0.6386  1.0118 </span>

    <span class="hljs-comment"># Coefficients:</span>
    <span class="hljs-comment">#             Estimate Std. Error t value Pr(&gt;|t|)    </span>
    <span class="hljs-comment"># (Intercept) 12.290909   0.749146  16.407 5.17e-08 ***</span>
    <span class="hljs-comment"># Lotsize     -0.030773   0.003571  -8.616 1.22e-05 ***</span>
    <span class="hljs-comment"># ---</span>
    <span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

    <span class="hljs-comment"># Residual standard error: 0.7491 on 9 degrees of freedom</span>
    <span class="hljs-comment"># Multiple R-squared:  0.8919,    Adjusted R-squared:  0.8799 </span>
    <span class="hljs-comment"># F-statistic: 74.24 on 1 and 9 DF,  p-value: 1.218e-05</span>


    <span class="hljs-comment"># Visalize the linear regression fit:</span>
    plot_ly(data,x=~Lotsize, 
                y=~Cost, 
                type=<span class="hljs-string">"scatter"</span>) %&gt;% add_lines(x = ~Lotsize, y = fitted(fit))

    <span class="hljs-comment"># Xbar here is called the Knot value.</span>
    <span class="hljs-comment"># Using Xbar = 200, manipulate the data</span>
    data$Xbar &lt;- ifelse(data$Lotsize&gt;<span class="hljs-number">200</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)
    data$diff &lt;- data$Lotsize - <span class="hljs-number">200</span>
    data$X &lt;- data$diff*data$Xbar

    data
    
    <span class="hljs-comment"># Output:</span>
    <span class="hljs-comment">#   Lotsize Cost    Xbar diff X</span>
    <span class="hljs-comment"># 1      100 9.73    0 -100   0</span>
    <span class="hljs-comment"># 2      120 9.61    0  -80   0</span>
    <span class="hljs-comment"># 3      140 8.15    0  -60   0</span>
    <span class="hljs-comment"># 4      160 6.98    0  -40   0</span>
    <span class="hljs-comment"># 5      180 5.87    0  -20   0</span>
    <span class="hljs-comment"># 6      200 4.98    0    0   0</span>
    <span class="hljs-comment"># 7      220 5.09    1   20  20</span>
    <span class="hljs-comment"># 8      240 4.79    1   40  40</span>
    <span class="hljs-comment"># 9      260 4.02    1   60  60</span>
    <span class="hljs-comment"># 10     280 4.46    1   80  80</span>
    <span class="hljs-comment"># 11     300 3.82    1  100 100</span>

    <span class="hljs-comment"># Fit the linear spline regression</span>
    <span class="hljs-comment"># The X in the equation below is (x-xbar)*Xk</span>
    reg &lt;- lm(Cost ~ Lotsize + X, data = data)

    plot_ly(data,x=~Lotsize,
            y=~Cost,
            type=<span class="hljs-string">"scatter"</span>) %&gt;% add_lines(x =  ~Lotsize, y = fitted(reg))

    summary(reg)
    



    <span class="hljs-comment">### Yokesh Thirumoorthi (STAT 564 FINALS)</span>

    <span class="hljs-comment"># Output:</span>

    <span class="hljs-comment"># Residuals:</span>
    <span class="hljs-comment">#     Min       1Q   Median       3Q      Max </span>
    <span class="hljs-comment"># -0.37596 -0.16641 -0.09677  0.20363  0.51734 </span>

    <span class="hljs-comment"># Coefficients:</span>
    <span class="hljs-comment">#             Estimate Std. Error t value Pr(&gt;|t|)    </span>
    <span class="hljs-comment"># (Intercept) 15.116481   0.535383  28.235 2.67e-09 ***</span>
    <span class="hljs-comment"># Lotsize     -0.050199   0.003332 -15.065 3.73e-07 ***</span>
    <span class="hljs-comment"># X            0.038852   0.005946   6.534 0.000181 ***</span>
    <span class="hljs-comment"># ---</span>
    <span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

    <span class="hljs-comment"># Residual standard error: 0.3157 on 8 degrees of freedom</span>
    <span class="hljs-comment"># Multiple R-squared:  0.9829,    Adjusted R-squared:  0.9787 </span>
    <span class="hljs-comment"># F-statistic: 230.4 on 2 and 8 DF,  p-value: 8.474e-08</span>

    
    <span class="hljs-comment"># Above results can also be obtained using Segmented package in R:</span>
    fit_seg &lt;- segmented(fit, seg.Z = ~Quantity, psi = list(Quantity=<span class="hljs-number">200</span>))

    plot_ly(data,x=~Quantity,
            y=~Sales,
            type=<span class="hljs-string">"scatter"</span>) %&gt;% add_lines(x =  ~Quantity, y = fitted(fit_seg))

    summary(fit_seg)
    <span class="hljs-comment">#Output:</span>

    <span class="hljs-comment"># Estimated Break-Point(s):</span>
    <span class="hljs-comment">#               Est. St.Err</span>
    <span class="hljs-comment"># psi1.Quantity 195.766 10.524</span>

    <span class="hljs-comment"># Meaningful coefficients of the linear terms:</span>
    <span class="hljs-comment">#             Estimate Std. Error t value Pr(&gt;|t|)    </span>
    <span class="hljs-comment"># (Intercept) 15.313000   0.753708  20.317 1.75e-07 ***</span>
    <span class="hljs-comment"># Lotsize     -0.051750   0.005277  -9.807 2.43e-05 ***</span>
    <span class="hljs-comment"># U1.Quantity  0.039664   0.006615   5.996       NA    </span>
    <span class="hljs-comment"># ---</span>
    <span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

    <span class="hljs-comment"># Residual standard error: 0.3337 on 7 degrees of freedom</span>
    <span class="hljs-comment"># Multiple R-Squared: 0.9833,  Adjusted R-squared: 0.9762 </span>

    <span class="hljs-comment"># Convergence attained in 2 iter. (rel. change 1.6406e-15)</span>
</div></code></pre>
<p><strong>Visualize the Dataset</strong></p>
<p align="left">
  <img src="file:////Users/mbpro/College/STAT/LRA/finalQ1_scatterplot.png" width="450" title="hover text">
</p>
<p><br><br><br><br>
<br><br><br><br></p>
<h3 id="yokesh-thirumoorthi-stat-564-finals-1">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<p><strong>Visalize the linear regression fit</strong></p>
<p align="left">
  <img src="file:////Users/mbpro/College/STAT/LRA/finalQ1_slr.png" width="450" title="hover text">
</p>
<p><strong>Visalize the spline fit</strong></p>
<p align="left">
  <img src="file:////Users/mbpro/College/STAT/LRA/finalQ1_spline2.png" width="450" title="hover text">
</p>
<p><strong>Comparing Results:</strong></p>
<p>The model using linear spline</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mn>15.31</mn><mi mathvariant="normal">−</mi><mi mathvariant="normal">.</mi><mn>05</mn><mi>x</mi><mo>+</mo><mn>0.039</mn><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mn>200</mn><msup><mo stretchy="false">)</mo><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">\hat y = 15.31 − .05x + 0.039(x-200)^1
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mord">.</span><span class="mord">3</span><span class="mord">1</span><span class="mord">−</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">3</span><span class="mord">9</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>The test</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">H_0:\beta_{1}=0
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span></span></p>
<p>which gives a t-value = 6.5 and p-value = 0.000</p>
<p>The R2 obtained using simple linear regression fit is</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>R</mi><mn>2</mn></msup><mo>=</mo><mn>89.19</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">R^2 = 89.19\%
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8641079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">8</span><span class="mord">9</span><span class="mord">.</span><span class="mord">1</span><span class="mord">9</span><span class="mord">%</span></span></span></span></span></p>
<p>The R2 obtained using linear spline fit is</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>R</mi><mn>2</mn></msup><mo>=</mo><mn>98.3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">R^2 = 98.3\%
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8641079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">9</span><span class="mord">8</span><span class="mord">.</span><span class="mord">3</span><span class="mord">%</span></span></span></span></span></p>
<p>Since the R2 obtained using linear spline fit is better, the data support the use
of linear spline model</p>
<p><br><br><br><br><br>
<br><br><br><br><br></p>
<h3 id="yokesh-thirumoorthi-stat-564-finals-2">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<h4 id="question-2">Question 2</h4>
<pre><code class="language-R"><div><span class="hljs-keyword">library</span>(readr) 
<span class="hljs-keyword">library</span>(car)
<span class="hljs-comment"># Read data from csv</span>
data &lt;- read_csv(<span class="hljs-string">"TableB3.csv"</span>)

data

<span class="hljs-comment"># a scatterplot matrix which include all the variables in the data set.</span>
<span class="hljs-comment"># Plot matrix of all variables.</span>
plot(data, col=<span class="hljs-string">"navy"</span>, main=<span class="hljs-string">"Matrix Scatterplot"</span>)
</div></code></pre>
<p><strong>Understanding Data:</strong></p>
<p>Inorder to get a high level overview of the data, i used the matrix scatter plot as shown below.</p>
<p align="left">
  <img src="file:////Users/mbpro/College/STAT/LRA/finalQ2_scatterplot.png" width="450" title="hover text">
</p>
<p>The above matrix plot helps to see the relationship between two columns and pattern in the datasets. For example, x1, x2, x3, x8, x9 and x10 seem to have similiar relationships. From the plot, y seems to have the same pattern with x1, x2, x3, x8, x9 and x10. Also, y seems to follow similar pattern with x6, x7 and x11.</p>
<p>In order to find the best model for predicting the y using different predictors in data, I look upon residuals error, p-value for the performance of the model.</p>
<p><strong>Fitting Models</strong></p>
<pre><code class="language-R"><div><span class="hljs-comment"># Fit data to linear model</span>
fit1 &lt;- lm(y ~ ., data = data)

<span class="hljs-comment"># Print the model summary</span>
summary(fit1)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Residuals:</span>
<span class="hljs-comment">#     Min      1Q  Median      3Q     Max </span>
<span class="hljs-comment"># -5.3441 -1.6711 -0.4486  1.4906  5.2508 </span>

<span class="hljs-comment"># Coefficients:</span>
<span class="hljs-comment">#              Estimate Std. Error t value Pr(&gt;|t|)  </span>
<span class="hljs-comment"># (Intercept) 17.339838  30.355375   0.571   0.5749  </span>
<span class="hljs-comment"># x1          -0.075588   0.056347  -1.341   0.1964  </span>
<span class="hljs-comment"># x2          -0.069163   0.087791  -0.788   0.4411  </span>
<span class="hljs-comment"># x3           0.115117   0.088113   1.306   0.2078  </span>
<span class="hljs-comment"># x4           1.494737   3.101464   0.482   0.6357  </span>
<span class="hljs-comment"># x5           5.843495   3.148438   1.856   0.0799 .</span>
<span class="hljs-comment"># x6           0.317583   1.288967   0.246   0.8082  </span>
<span class="hljs-comment"># x7          -3.205390   3.109185  -1.031   0.3162  </span>
<span class="hljs-comment"># x8           0.180811   0.130301   1.388   0.1822  </span>
<span class="hljs-comment"># x9          -0.397945   0.323456  -1.230   0.2344  </span>
<span class="hljs-comment"># x10         -0.005115   0.005896  -0.868   0.3971  </span>
<span class="hljs-comment"># x11          0.638483   3.021680   0.211   0.8350  </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Residual standard error: 3.227 on 18 degrees of freedom</span>
<span class="hljs-comment">#   (2 observations deleted due to missingness)</span>
<span class="hljs-comment"># Multiple R-squared:  0.8355,    Adjusted R-squared:  0.7349 </span>
<span class="hljs-comment"># F-statistic:  8.31 on 11 and 18 DF,  p-value: 5.231e-05</span>
</div></code></pre>
<p>From the summary of fit1, I have the results of the model. From the model output I found that:</p>
<ul>
<li>
<p>The parameters - x2, x4, x6, x10 and x11 have t-value close to 0 and high pvalues. It shows that there is no significant relation with y.</p>
</li>
<li>
<p>The RSE is 3.227 where p-value is very small.</p>
</li>
</ul>
<p>The matrix scatterplot above shows that there is the high correlation between x1, x2, x3 and x10. When there are two or more variables strongly correlated it is called collinearity. I validate collinearity by using correlation matrix and VIF.</p>
<pre><code class="language-R"><div><span class="hljs-comment"># matrix of correlations between the variables</span>
cor(data, use = <span class="hljs-string">"complete.obs"</span>)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment">#              y         x1         x2         x3          x4         x5</span>
<span class="hljs-comment"># y    1.0000000 -0.8721701 -0.7968304 -0.8495915  0.42237247  0.6347500</span>
<span class="hljs-comment"># x1  -0.8721701  1.0000000  0.9408473  0.9891628 -0.34697246 -0.6720903</span>
<span class="hljs-comment"># x2  -0.7968304  0.9408473  1.0000000  0.9643592 -0.28989951 -0.5509642</span>
<span class="hljs-comment"># x3  -0.8495915  0.9891628  0.9643592  1.0000000 -0.32599915 -0.6728661</span>
<span class="hljs-comment"># x4   0.4223725 -0.3469725 -0.2898995 -0.3259992  1.00000000  0.4137808</span>
<span class="hljs-comment"># x5   0.6347500 -0.6720903 -0.5509642 -0.6728661  0.41378081  1.0000000</span>
<span class="hljs-comment"># x6  -0.4718055  0.6427984  0.7614190  0.6531263  0.03748643 -0.2195283</span>
<span class="hljs-comment"># x7   0.7077682 -0.7719151 -0.6259445 -0.7461800  0.55823570  0.8717662</span>
<span class="hljs-comment"># x8  -0.7528208  0.8623681  0.8027387  0.8641224 -0.30415026 -0.5613315</span>
<span class="hljs-comment"># x9  -0.7629952  0.7974811  0.7105117  0.7881284 -0.37817358 -0.4534470</span>
<span class="hljs-comment"># x10 -0.8528801  0.9515520  0.8878810  0.9434871 -0.35845879 -0.5798617</span>
<span class="hljs-comment"># x11 -0.7212809  0.8244446  0.7086735  0.8012765 -0.44054570 -0.7546650</span>
<span class="hljs-comment">#              x6         x7         x8         x9        x10        x11</span>
<span class="hljs-comment"># y   -0.47180548  0.7077682 -0.7528208 -0.7629952 -0.8528801 -0.7212809</span>
<span class="hljs-comment"># x1   0.64279836 -0.7719151  0.8623681  0.7974811  0.9515520  0.8244446</span>
<span class="hljs-comment"># x2   0.76141897 -0.6259445  0.8027387  0.7105117  0.8878810  0.7086735</span>
<span class="hljs-comment"># x3   0.65312630 -0.7461800  0.8641224  0.7881284  0.9434871  0.8012765</span>
<span class="hljs-comment"># x4   0.03748643  0.5582357 -0.3041503 -0.3781736 -0.3584588 -0.4405457</span>
<span class="hljs-comment"># x5  -0.21952829  0.8717662 -0.5613315 -0.4534470 -0.5798617 -0.7546650</span>
<span class="hljs-comment"># x6   1.00000000 -0.2756386  0.4220680  0.3003862  0.5203669  0.3954893</span>
<span class="hljs-comment"># x7  -0.27563863  1.0000000 -0.6552065 -0.6551300 -0.7058126 -0.8506963</span>
<span class="hljs-comment"># x8   0.42206800 -0.6552065  1.0000000  0.8831512  0.9554541  0.6824919</span>
<span class="hljs-comment"># x9   0.30038618 -0.6551300  0.8831512  1.0000000  0.8994711  0.6326677</span>
<span class="hljs-comment"># x10  0.52036693 -0.7058126  0.9554541  0.8994711  1.0000000  0.7530353</span>
<span class="hljs-comment"># x11  0.39548928 -0.8506963  0.6824919  0.6326677  0.7530353  1.0000000</span>

car::vif(fit1)
<span class="hljs-comment">#Output</span>
<span class="hljs-comment">#         x1         x2         x3         x4         x5         x6         x7 </span>
<span class="hljs-comment"># 119.487804  42.800811 149.234409   2.060036   7.729187   5.324730  11.761341 </span>
<span class="hljs-comment">#         x8         x9        x10        x11 </span>
<span class="hljs-comment">#  20.917632   9.397108  85.744344   5.145052 </span>
</div></code></pre>
<p>From the correlation, I can see that there is a strong relation between x1, x2, x3, x8, x9 and x10. The y is also strongly correlated to x1, x2, x3, x8, x9 and x10. This situation is called collinearity. The problem of collinearity in the response is that it is difficult to find the individual effect on response. We should drop use only one of the collinear variables.</p>
<p>Out of x1, x2, x3, x8, x9 and x10, the output of the first model shows that x8 and y have a highly significant relation. I use x1 out of the other collinear variables in the next model.</p>
<p>Also, from fit1, I see x4, x6 and x11 have no significance to model.</p>
<p><br><br><br><br><br>
<br><br><br><br><br></p>
<h3 id="yokesh-thirumoorthi-stat-564-finals-3">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<pre><code class="language-R"><div>
<span class="hljs-comment"># Fit data to linear model</span>
fit2 &lt;- lm(y ~ x1 + x5 + x7, data = data)

<span class="hljs-comment"># Print the fit2 summary</span>
summary(fit2)

<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Residuals:</span>
<span class="hljs-comment">#     Min      1Q  Median      3Q     Max </span>
<span class="hljs-comment"># -6.7887 -1.9555  0.2436  1.6370  6.8531 </span>

<span class="hljs-comment"># Coefficients:</span>
<span class="hljs-comment">#              Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="hljs-comment"># (Intercept) 29.492027   6.655192   4.431 0.000131 ***</span>
<span class="hljs-comment"># x1          -0.043652   0.007756  -5.628    5e-06 ***</span>
<span class="hljs-comment"># x5           0.347945   2.057862   0.169 0.866949    </span>
<span class="hljs-comment"># x7           0.631227   2.006266   0.315 0.755377    </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Residual standard error: 3.149 on 28 degrees of freedom</span>
<span class="hljs-comment"># Multiple R-squared:  0.7757,    Adjusted R-squared:  0.7517 </span>
<span class="hljs-comment"># F-statistic: 32.28 on 3 and 28 DF,  p-value: 3.145e-09</span>

car::vif(fit2)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment">#       x1       x5       x7 </span>
<span class="hljs-comment"># 2.585583 3.475845 5.366865 </span>
</div></code></pre>
<p>The VIF output show s that I have almost got rid of collinearity problem (execpt for x7 has VIF &gt; 5).
In this model, I find x1 predictor p-value is highly significant. After excluding the collinear variable the F- statistic improved from 8.31 to 32.28 which is a good sign. But there is no improvement on RSE and adjusted R squared value. Let’s plot the residuals:</p>
<p align="left">
  <img src="file:////Users/mbpro/College/STAT/LRA/finalQ2_fit2_res.png" width="450" title="hover text">
</p>
<ul>
<li><strong>Residuals vs Fitted:</strong>
The plot of residuals versus fitted values indicates linearity in the data. A horizontal line, without distinct patterns is an indication for a linear relationship. And for this model it seems to have a pattern fitted with the residuals and fitted values. And it indicates a non-linear relationship in the data.</li>
</ul>
<p>This plot also shows some of the outliers lying far away from the middle of the graph.</p>
<ul>
<li><strong>Normal Q-Q:</strong>
This plot is used to examine whether the residuals are normally distributed. It’s good if residuals points follow the straight dashed line. And this model has its residuals normally distributed except for the tail data (the outliers).</li>
</ul>
<h3 id="yokesh-thirumoorthi-stat-564-finals-4">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<ul>
<li>
<p><strong>Scale-Location (or Spread-Location):</strong> This plot is used to check the homogeneity of variance of the residuals (homoscedasticity). Horizontal line with equally spread points is a good indication of homoscedasticity. This is not the case in this model and hence the model has a heteroscedasticity problem.</p>
</li>
<li>
<p><strong>Standardized Residuals vs Leverage:</strong> This plot is used to identify influential cases (outliers), that is extreme values that might influence the regression results when included or excluded from the analysis. This plot of standardized residuals versus leverage indicates the presence of a few outliers (example: point 12 and point 27)</p>
</li>
</ul>
<p>I try log transformation on both predictors and the response value and see how the performance of model changes. In the next model, I use the natural log to the y using log() and see the change in performance of the model.</p>
<pre><code class="language-R"><div>fit3 &lt;- lm(log(y) ~ x1 + x5 + x7, data = data)
summary(fit3)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Residuals:</span>
<span class="hljs-comment">#       Min        1Q    Median        3Q       Max </span>
<span class="hljs-comment"># -0.279565 -0.105526  0.009649  0.084624  0.237414 </span>

<span class="hljs-comment"># Coefficients:</span>
<span class="hljs-comment">#               Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="hljs-comment"># (Intercept)  3.6371922  0.2889610  12.587 4.79e-13 ***</span>
<span class="hljs-comment"># x1          -0.0021787  0.0003368  -6.469 5.22e-07 ***</span>
<span class="hljs-comment"># x5          -0.0786753  0.0893500  -0.881    0.386    </span>
<span class="hljs-comment"># x7           0.0563762  0.0871098   0.647    0.523    </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Residual standard error: 0.1367 on 28 degrees of freedom</span>
<span class="hljs-comment"># Multiple R-squared:  0.7997,    Adjusted R-squared:  0.7783 </span>
<span class="hljs-comment"># F-statistic: 37.27 on 3 and 28 DF,  p-value: 6.522e-10</span>
plot(fit3)
</div></code></pre>
<p>The performance of the model is unaffected. The Adjusted R-squared  and F-statistic has not increased.</p>
<pre><code class="language-R"><div>
fit4 &lt;- lm((y) ~ log(x1) + log(x5) + log(x7), data = data)
summary(fit4)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Residuals:</span>
<span class="hljs-comment">#     Min      1Q  Median      3Q     Max </span>
<span class="hljs-comment"># -6.6366 -1.8211  0.2634  1.6410  4.4030 </span>

<span class="hljs-comment"># Coefficients:</span>
<span class="hljs-comment">#             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="hljs-comment"># (Intercept)  109.360     14.965   7.308 5.89e-08 ***</span>
<span class="hljs-comment"># log(x1)      -13.898      1.690  -8.224 5.97e-09 ***</span>
<span class="hljs-comment"># log(x5)       -5.495      4.738  -1.160    0.256    </span>
<span class="hljs-comment"># log(x7)       -5.062      6.160  -0.822    0.418    </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Residual standard error: 2.411 on 28 degrees of freedom</span>
<span class="hljs-comment"># Multiple R-squared:  0.8685,    Adjusted R-squared:  0.8544 </span>
<span class="hljs-comment"># F-statistic: 61.62 on 3 and 28 DF,  p-value: 1.885e-12</span>
plot(fit4, which =<span class="hljs-number">1</span>)
</div></code></pre>
<p>Here the performance of the model has increased. The Adjusted R-squared raised to 0.8544 and F-statistic is increased to 61.62.</p>
<p>Now, build regression model from a set of candidate predictor variables by entering and removing predictors based on p values, in a stepwise manner until there is no variable left to enter or remove any more.</p>
<pre><code class="language-R"><div>ols_step_both_p(fit4)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Stepwise Selection Method   </span>
<span class="hljs-comment"># ---------------------------</span>

<span class="hljs-comment"># Candidate Terms: </span>

<span class="hljs-comment"># 1. log(x1) </span>
<span class="hljs-comment"># 2. log(x5) </span>

<span class="hljs-comment"># We are selecting variables based on p value...</span>

<span class="hljs-comment"># Variables Entered/Removed: </span>

<span class="hljs-comment"># ✔ log(x1) </span>
<span class="hljs-comment"># ✔ log(x5) </span>


<span class="hljs-comment"># Final Model Output </span>
<span class="hljs-comment"># ------------------</span>

<span class="hljs-comment">#                         Model Summary                          </span>
<span class="hljs-comment"># --------------------------------------------------------------</span>
<span class="hljs-comment"># R                       0.930       RMSE                2.398 </span>
<span class="hljs-comment"># R-Squared               0.865       Coef. Var          11.856 </span>
<span class="hljs-comment"># Adj. R-Squared          0.856       MSE                 5.749 </span>
<span class="hljs-comment"># Pred R-Squared          0.834       MAE                 1.802 </span>
<span class="hljs-comment"># --------------------------------------------------------------</span>
<span class="hljs-comment">#  RMSE: Root Mean Square Error </span>
<span class="hljs-comment">#  MSE: Mean Square Error </span>
<span class="hljs-comment">#  MAE: Mean Absolute Error </span>

<span class="hljs-comment">#                                ANOVA                                 </span>
<span class="hljs-comment"># --------------------------------------------------------------------</span>
<span class="hljs-comment">#                 Sum of                                              </span>
<span class="hljs-comment">#                Squares        DF    Mean Square      F         Sig. </span>
<span class="hljs-comment"># --------------------------------------------------------------------</span>
<span class="hljs-comment"># Regression    1070.829         2        535.415    93.135    0.0000 </span>
<span class="hljs-comment"># Residual       166.715        29          5.749                     </span>
<span class="hljs-comment"># Total         1237.544        31                                    </span>
<span class="hljs-comment"># --------------------------------------------------------------------</span>

<span class="hljs-comment">#                                     Parameter Estimates                                      </span>
<span class="hljs-comment"># --------------------------------------------------------------------------------------------</span>
<span class="hljs-comment">#       model       Beta    Std. Error    Std. Beta       t        Sig       lower      upper </span>
<span class="hljs-comment"># --------------------------------------------------------------------------------------------</span>
<span class="hljs-comment"># (Intercept)    100.293        10.052                   9.977    0.000     79.734    120.851 </span>
<span class="hljs-comment">#     log(x1)    -12.910         1.181       -1.056    -10.935    0.000    -15.325    -10.496 </span>
<span class="hljs-comment">#     log(x5)     -7.707         3.877       -0.192     -1.988    0.056    -15.636      0.223 </span>
<span class="hljs-comment"># --------------------------------------------------------------------------------------------</span>

<span class="hljs-comment">#                              Stepwise Selection Summary                              </span>
<span class="hljs-comment"># ------------------------------------------------------------------------------------</span>
<span class="hljs-comment">#                      Added/                   Adj.                                      </span>
<span class="hljs-comment"># Step    Variable    Removed     R-Square    R-Square     C(p)       AIC        RMSE     </span>
<span class="hljs-comment"># ------------------------------------------------------------------------------------</span>
<span class="hljs-comment">#    1    log(x1)     addition       0.847       0.842    4.9510    153.7173    2.5128    </span>
<span class="hljs-comment">#    2    log(x5)     addition       0.865       0.856    3.0000    151.6296    2.3977    </span>
<span class="hljs-comment"># ------------------------------------------------------------------------------------</span>
</div></code></pre>
<p>Fit the model with selected parameters only.</p>
<pre><code class="language-R"><div>fit5 &lt;- lm(log(y) ~ log(x1) + log(x5), data = data)
summary(fit5)
<span class="hljs-comment">#Output</span>
<span class="hljs-comment"># Residuals:</span>
<span class="hljs-comment">#      Min       1Q   Median       3Q      Max </span>
<span class="hljs-comment"># -0.26474 -0.05966  0.01784  0.07172  0.19876 </span>

<span class="hljs-comment"># Coefficients:</span>
<span class="hljs-comment">#             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="hljs-comment"># (Intercept)   7.1097     0.4615  15.406 1.68e-15 ***</span>
<span class="hljs-comment"># log(x1)      -0.6324     0.0542 -11.669 1.78e-12 ***</span>
<span class="hljs-comment"># log(x5)      -0.5794     0.1780  -3.255  0.00288 ** </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Residual standard error: 0.1101 on 29 degrees of freedom</span>
<span class="hljs-comment"># Multiple R-squared:  0.8655,    Adjusted R-squared:  0.8563 </span>
<span class="hljs-comment"># F-statistic: 93.33 on 2 and 29 DF,  p-value: 2.317e-13</span>
plot(fit5, which =<span class="hljs-number">1</span>)
</div></code></pre>
<p><br><br></p>
<h3 id="yokesh-thirumoorthi-stat-564-finals-5">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<p>The performance of the model is increased. The Adjusted R-squared raised to 0.8563 and F-statistic is increased to 93.33. The p-value of the predictors is significant. Also the Residual standard error has reduced to 0.1.</p>
<p>Outliers Observation:</p>
<p align="left">
  <img src="file:////Users/mbpro/College/STAT/LRA/finalQ2_fit5_res.png" width="450" title="hover text">
</p>
<p>It is still observered that the are some outliers - point 6, 15, 22, which if eleminated could improve our model. Also from Normal q-q, this model has its residuals normally distributed except for the tail data (the outliers).</p>
<pre><code class="language-R"><div>fit6 &lt;- lm(log(y) ~ log(x1) + log(x5), data = data[ -c(<span class="hljs-number">6</span>, <span class="hljs-number">15</span>, <span class="hljs-number">22</span>), ])
summary(fit6)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Residuals:</span>
<span class="hljs-comment">#      Min       1Q   Median       3Q      Max </span>
<span class="hljs-comment"># -0.15466 -0.03867  0.01436  0.05199  0.12501 </span>

<span class="hljs-comment"># Coefficients:</span>
<span class="hljs-comment">#             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="hljs-comment"># (Intercept)  6.93889    0.36089  19.227  &lt; 2e-16 ***</span>
<span class="hljs-comment"># log(x1)     -0.62182    0.04258 -14.605 4.81e-14 ***</span>
<span class="hljs-comment"># log(x5)     -0.46913    0.13866  -3.383  0.00228 ** </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Residual standard error: 0.0831 on 26 degrees of freedom</span>
<span class="hljs-comment"># Multiple R-squared:  0.9217,    Adjusted R-squared:  0.9157 </span>
<span class="hljs-comment"># F-statistic: 153.1 on 2 and 26 DF,  p-value: 4.128e-15</span>
</div></code></pre>
<p>Thus in this final model, we have, the performance of the model is again increased. The Adjusted R-squared raised to 0.9157 and F-statistic is increased to 153.1 from 93.33 in previous fit. The p-value of the predictors is significant. Also the Residual standard error has reduced to 0.0831.</p>
<p>ANOVA:</p>
<pre><code class="language-R"><div>anova(fit6)
<span class="hljs-comment">#Output</span>
<span class="hljs-comment"># Analysis of Variance Table</span>

<span class="hljs-comment"># Response: log(y)</span>
<span class="hljs-comment">#           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span>
<span class="hljs-comment"># log(x1)    1 2.03568 2.03568 294.798 1.049e-15 ***</span>
<span class="hljs-comment"># log(x5)    1 0.07904 0.07904  11.447  0.002279 ** </span>
<span class="hljs-comment"># Residuals 26 0.17954 0.00691            </span>
</div></code></pre>
<p>The final model is</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mn>6.94</mn><mo>−</mo><mn>0.62</mn><mo>∗</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mn>0.47</mn><mo>∗</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mn>5</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">log(\hat y) = 6.94 - 0.62 * log(x1) - 0.47 * log(x5)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mord">.</span><span class="mord">9</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">6</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span></p>
<h3 id="yokesh-thirumoorthi-stat-564-finals-6">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<h4 id="question-3">Question 3</h4>
<pre><code class="language-R"><div><span class="hljs-keyword">library</span>(readr) 
<span class="hljs-keyword">library</span>(lmridge)

<span class="hljs-comment"># Read data from csv</span>
data &lt;- read_csv(<span class="hljs-string">"TableB3.csv"</span>)

mod &lt;- lmridge(y~., data = data)

kest(mod)
<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Ridge k from different Authors</span>

<span class="hljs-comment">#                               k values</span>
<span class="hljs-comment"># Thisted (1976):                0.01301</span>
<span class="hljs-comment"># Dwividi &amp; Srivastava (1978):   0.00145</span>
<span class="hljs-comment"># LW (lm.ridge)                  2.79820</span>
<span class="hljs-comment"># LW (1976)                      0.11400</span>
<span class="hljs-comment"># HKB (1975)                     0.01590</span>
<span class="hljs-comment"># Kibria (2003) (AM)             0.84498</span>
<span class="hljs-comment"># Minimum GCV at                 0.00000</span>
<span class="hljs-comment"># Minimum CV at                  0.00000</span>
<span class="hljs-comment"># Kibria 2003 (GM):              0.43061</span>
<span class="hljs-comment"># Kibria 2003 (MED):             0.11430</span>
<span class="hljs-comment"># Muniz et al. 2009 (KM2):      19.51507</span>
<span class="hljs-comment"># Muniz et al. 2009 (KM3):      25.90658</span>
<span class="hljs-comment"># Muniz et al. 2009 (KM4):       1.52390</span>
<span class="hljs-comment"># Muniz et al. 2009 (KM5):       0.65621</span>
<span class="hljs-comment"># Muniz et al. 2009 (KM6):       2.95788</span>
<span class="hljs-comment"># Mansson et al. 2012 (KMN8):   19.57818</span>
<span class="hljs-comment"># Mansson et al. 2012 (KMN9):    0.63647</span>
<span class="hljs-comment"># Mansson et al. 2012 (KMN10):   3.72794</span>
<span class="hljs-comment"># Mansson et al. 2012 (KMN11):   0.26824</span>
<span class="hljs-comment"># Mansson et al. 2012 (KMN12):   3.34905</span>
<span class="hljs-comment"># Dorugade et al. 2010:          0.00000</span>
<span class="hljs-comment"># Dorugade et al. 2014:          0.00000</span>

<span class="hljs-comment"># HKB (1975) = 0.01590</span>
HKB &lt;- kest(mod)$HKB

mod &lt;- lmridge(y~., data = data, K = HKB, scaling = <span class="hljs-string">"sc"</span>)

summary(mod)

<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># Call:</span>
<span class="hljs-comment"># lmridge.default(formula = y ~ ., data = data, K = 0.0159, scaling = "sc")</span>

<span class="hljs-comment"># Coefficients: for Ridge parameter K= 0.0159 </span>
<span class="hljs-comment">#             Estimate Estimate (Sc) StdErr (Sc) t-value (Sc) Pr(&gt;|t|)  </span>
<span class="hljs-comment"># Intercept    14.4905    64223.0887  38121.4547       1.6847   0.1073  </span>
<span class="hljs-comment"># x1           -0.0307      -19.2348      9.9544      -1.9323   0.0673 .</span>
<span class="hljs-comment"># x2           -0.0074       -1.7682      9.6909      -0.1825   0.8570  </span>
<span class="hljs-comment"># x3            0.0141        6.2921      9.5624       0.6580   0.5179  </span>
<span class="hljs-comment"># x4            2.3160        3.4583      3.9598       0.8733   0.3926  </span>
<span class="hljs-comment"># x5            3.4462        9.8190      6.6100       1.4855   0.1527  </span>
<span class="hljs-comment"># x6           -0.0702       -0.4055      5.7145      -0.0710   0.9441  </span>
<span class="hljs-comment"># x7           -1.8342       -6.5280      8.2193      -0.7942   0.4362  </span>
<span class="hljs-comment"># x8            0.1185       13.4182      8.2040       1.6356   0.1173  </span>
<span class="hljs-comment"># x9           -0.3094       -9.4601      7.4952      -1.2622   0.2211  </span>
<span class="hljs-comment"># x10          -0.0034      -17.0367     10.4523      -1.6299   0.1185  </span>
<span class="hljs-comment"># x11           0.3750        0.9084      6.3993       0.1419   0.8885  </span>
<span class="hljs-comment"># ---</span>
<span class="hljs-comment"># Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>

<span class="hljs-comment"># Ridge Summary</span>
<span class="hljs-comment">#         R2     adj-R2   DF ridge          F        AIC        BIC </span>
<span class="hljs-comment">#   0.787100   0.675100   8.598640   8.487379  75.106545 189.190858 </span>
<span class="hljs-comment"># Ridge minimum MSE= 3984.056 at K= 0.0159 </span>
<span class="hljs-comment"># P-value for F-test ( 8.59864 , 20.28187 ) = 4.069372e-05 </span>
<span class="hljs-comment"># -------------------------------------------------------------------</span>
</div></code></pre>
<p><br><br><br></p>
<h3 id="yokesh-thirumoorthi-stat-564-finals-7">Yokesh Thirumoorthi (STAT 564 FINALS)</h3>
<p>The fitted model with estimated parameters is</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mn>14.49</mn><mo>−</mo><mn>0.03</mn><mi>x</mi><mn>1</mn><mo>−</mo><mn>0.007</mn><mi>x</mi><mn>2</mn><mo>+</mo><mn>0.0141</mn><mi>x</mi><mn>3</mn><mo>+</mo><mn>2.3160</mn><mi>x</mi><mn>4</mn><mo>+</mo><mn>3.4464</mn><mi>x</mi><mn>5</mn><mo>−</mo><mn>0.0702</mn><mi>x</mi><mn>6</mn><mo>−</mo><mn>1.8343</mn><mi>x</mi><mn>7</mn><mo>+</mo><mn>0.1185</mn><mi>x</mi><mn>8</mn><mo>−</mo><mn>0.3094</mn><mi>x</mi><mn>9</mn><mo>−</mo><mn>0.0034</mn><mi>x</mi><mn>10</mn><mo>+</mo><mn>0.3751</mn><mi>x</mi><mn>11</mn></mrow><annotation encoding="application/x-tex">\hat y = 14.49-0.03x1-0.007x2+0.0141x3+2.3160x4+3.4464x5-0.0702x6-1.8343x7+0.1185x8-0.3094x9-0.0034x10+0.3751x11
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">4</span><span class="mord">.</span><span class="mord">4</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">3</span><span class="mord mathdefault">x</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">7</span><span class="mord mathdefault">x</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mord">4</span><span class="mord">1</span><span class="mord mathdefault">x</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">3</span><span class="mord">1</span><span class="mord">6</span><span class="mord">0</span><span class="mord mathdefault">x</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">4</span><span class="mord">4</span><span class="mord">6</span><span class="mord">4</span><span class="mord mathdefault">x</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">7</span><span class="mord">0</span><span class="mord">2</span><span class="mord mathdefault">x</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">8</span><span class="mord">3</span><span class="mord">4</span><span class="mord">3</span><span class="mord mathdefault">x</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">1</span><span class="mord">8</span><span class="mord">5</span><span class="mord mathdefault">x</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">0</span><span class="mord">9</span><span class="mord">4</span><span class="mord mathdefault">x</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">3</span><span class="mord">4</span><span class="mord mathdefault">x</span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">7</span><span class="mord">5</span><span class="mord">1</span><span class="mord mathdefault">x</span><span class="mord">1</span><span class="mord">1</span></span></span></span></span></p>
<p>Without the use of ridge regression the SSE is 0.179 and MSE is 0.0069. But with ridge regreesion it is observered that MSE is 3984.056 at K= 0.0159</p>
<p>Without the use of ridge regression The R2 is 92.17% and with ridge regression it is 78.71%, which is an decrease of around 15%.</p>

    </body>
    </html>