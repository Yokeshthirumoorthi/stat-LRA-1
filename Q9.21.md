#### Question 5.13

**TableB21.csv**

| Y     | X1  | X2  | X3  | X4  |
| ----- | --- | --- | --- | --- |
| 78.5  | 7   | 26  | 6   | 60  |
| 74.3  | 1   | 29  | 15  | 52  |
| 104.3 | 11  | 56  | 8   | 20  |
| 87.6  | 11  | 31  | 8   | 47  |
| 95.9  | 7   | 52  | 6   | 33  |
| 109.2 | 11  | 55  | 9   | 22  |
| 102.7 | 3   | 71  | 17  | 6   |
| 72.5  | 1   | 31  | 22  | 44  |
| 93.1  | 2   | 54  | 18  | 22  |
| 115.9 | 21  | 47  | 4   | 26  |
| 83.8  | 1   | 40  | 23  | 34  |
| 113.3 | 11  | 66  | 9   | 12  |
| 109.4 | 10  | 68  | 8   | 12  |

```R
# Read data from csv
data <- read_csv("TableB21.csv")

# Linear model without PCA
lmodel.none <- lm(Y ~ ., data = data)
summary(lmodel.none)

# Extracting the dependent variable y to data.y and removing it from the original dataframe.
data.y <- data$Y
data$Y <- NULL

# Understand variable correlation
res <- cor(data, method="pearson")
corrplot::corrplot(res, method= "color", order = "hclust", tl.pos = 'n')

# Do data normalization
data.norm <- scale(data)
data.y.norm <- scale(data.y)

# Get summary of principle components
data.pca1 <- prcomp(data.norm, center=TRUE, scale.=TRUE)
summary(data.pca1)

# Look at the eigen values
data.pca1$sdev

# Understand principle components correlation
res1 <- cor(data.pca1$x, method="pearson")
corrplot::corrplot(res1, method= "color", order = "hclust", tl.pos = 'n')

#  Combine both principle components and y
pcs <- as.data.frame(data.pca1$x)
ols.data <- cbind(data.y.norm, pcs)

# Perform principle component regression
lmodel <- lm(data.y.norm ~ PC1 + PC2, data = ols.data)
summary(lmodel)

```